# Simulation code for "On the consistency of bootstrap for matching estimators"
This repository contains the simulation code used in the Biometrika revision to evaluate the use of bootstrap on bias-corrected matching estimator on two empirical designs:

- **LDW** (Lalonde/Dehejia–Wahba data): outcome `re78`, treatment `t`.
- **Shadish**: outcome `mathall`, treatment `vm`.

The pipeline runs Monte Carlo experiments on Slurm, merges per-task outputs, and produces CSV and LaTeX tables with coverage metrics.

---

## Repository layout
```
bmproject/
estimators.py
mc_runner_LDW.py
mc_runner_Shadish.py
postprocess_LDW.py
postprocess_Shadish.py
scripts/
run_mc_LDW_array.sbatch
run_mc_Shadish_array.sbatch
merge_LDW.sbatch
merge_Shadish.sbatch
postprocess_LDW.sbatch
postprocess_Shadish.sbatch
data/ # (not tracked) place input .feather files here
result/ # outputs: CSV / TeX / merged feather
requirements.txt
```
---

## Software environment

- Python 3.9+ with packages listed in `requirements.txt` (NumPy, pandas, SciPy, scikit-learn, pyarrow, tqdm, etc.).
- Optional: PyTorch is listed but **not** required by the runners.

Create and activate a virtual environment, then install dependencies:

```bash
module load Python                 # omit if not on a module-based cluster
python -m venv ~/venvs/BMproject
source ~/venvs/BMproject/bin/activate
python -m pip install --upgrade pip
pip install -r requirements.txt
```
You may reuse an existing venv if you already have one.

## Data

Large inputs are **not** tracked in the repo. Place the following files under `data/`:

- `data/exp_generated.feather`  (LDW): Simulated LaLonde data is generated by Athey, Imbens, Metzger, *et al.* (2024), and can be directly downloaded from [https://drive.google.com/drive/folders/1CCU1zuibrPOZHK6NAAAVrX5TKQZZOMTF](https://drive.google.com/drive/folders/1CCU1zuibrPOZHK6NAAAVrX5TKQZZOMTF).
- `data/shadish_generated.feather`  (Shadish): Simulated Shadish data is generated by Lin, Ding, and Han (2023), and can be directly downloaded from
[https://zenodo.org/records/8322609](https://zenodo.org/records/8322609)

## How to run (Slurm)

You can submit jobs with `sbatch`. The workflow is: run array jobs → merge → postprocess.

### Option A — submit step by step

```bash
# LDW
sbatch scripts/run_mc_LDW_array.sbatch
sbatch scripts/merge_LDW.sbatch
sbatch scripts/postprocess_LDW.sbatch

# Shadish
sbatch scripts/run_mc_Shadish_array.sbatch
sbatch scripts/merge_Shadish.sbatch
sbatch scripts/postprocess_Shadish.sbatch
```


### Option B — submit with dependencies (one shot per dataset)


```bash
# LDW chain
LDW=$(sbatch --parsable scripts/run_mc_LDW_array.sbatch)
LDW_MERGE=$(sbatch --parsable --dependency=afterok:$LDW scripts/merge_LDW.sbatch)
sbatch --dependency=afterok:$LDW_MERGE scripts/postprocess_LDW.sbatch

# Shadish chain
SH=$(sbatch --parsable scripts/run_mc_Shadish_array.sbatch)
SH_MERGE=$(sbatch --parsable --dependency=afterok:$SH scripts/merge_Shadish.sbatch)
sbatch --dependency=afterok:$SH_MERGE scripts/postprocess_Shadish.sbatch
```

Monitor with:
```bash
squeue -u $USER
```
Logs are written under `logs/`.

## Key settings

Both runners use sample sizes `N ∈ {600, 1200, 4800, 9600}`.  
The number of neighbors **M** is variable by default:

- Inline math: $M = \lfloor c \cdot N^{1/3} \rfloor$ with multipliers $c \in \{0.5, 1, 2, 5\}$.
- To change it, edit the `srun python ...` line in `scripts/run_mc_*.sbatch` and pass:
- 
```bash
  --M_poly_list "0.5,1,2,5"
```

Other important CLI flags (already set in the sbatch files):

- `--N_runs`: iterations per (N, M).
- `--N_workers`: Python worker processes (uses `--cpus-per-task`).
- `--B_boot`: stratified bootstrap replicates per iteration (percentile CIs).
- `--alphas`: e.g., `"0.10,0.05"` for 90%/95% intervals.
- `--out-root`, `--run-name`: where per-task outputs are written.

---

## Outputs

After merging:

- `result/out_LDW.feather`, `result/out_Shadish.feather` — concatenation of all per-task results with columns  
  `N, M, method, est, se, AIse, boot_lo_p90, boot_hi_p90, boot_lo_p95, boot_hi_p95, …`.

After post-processing:

- `result/LDW_res.csv`, `result/Shadish_res.csv` — Bias, SD, RMSE, MAE, and coverage (SE / AISE / Bootstrap), **grouped by (N, M)**.
- `result/Coverage_LDW.tex`, `result/Coverage_Shadish.tex` — LaTeX tables ready for the manuscript.

---

## Reproducibility notes

- **RNG seeding.** Each chunk’s base seed is deterministic in `(N, M, iter_counter, salt)`. The Slurm array index is passed as `--salt` to decorrelate tasks.
- **Bootstrap.** Stratified within treatment/control to preserve group sizes.
- **Alphas.** Post-processing requires alphas to include `0.10` and `0.05`.

---

## References

- Lin, Z., Ding, P., & Han, F. (2023). Estimation based on nearest neighbor matching: from density ratio to average treatment effect. *Econometrica*, 91(6), 2187–2217.

- Athey, S., Imbens, G. W., Metzger, J., et al. (2024). Using Wasserstein generative adversarial networks for the design of Monte Carlo simulations. *Journal of Econometrics*, 240(2), 105076.



## Contact

For questions or reproducibility issues, please open a GitHub issue or contact the maintainer.









